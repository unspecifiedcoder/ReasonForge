[
  {
    "task_id": "causal-infer-001",
    "problem": "A study finds that cities with more fire stations have more fires. A journalist concludes that fire stations cause fires. Identify the flaw in this reasoning and propose the correct causal model.",
    "domain": "causal",
    "difficulty": 2,
    "timeout_seconds": 120,
    "ground_truth": "This is a classic case of confounding (common cause). The correct causal model: City size → More fire stations AND City size → More fires. Larger cities build more fire stations AND have more fires (more buildings, more people). City size is a confounder. The correlation between fire stations and fires is spurious—it disappears when conditioning on city size (or population). The journalist commits the post hoc ergo propter hoc fallacy and confuses correlation with causation.",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["confounding", "spurious-correlation", "common-cause"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-002",
    "problem": "In an observational study, researchers want to estimate the causal effect of a college degree on earnings. They have data on education, earnings, parental income, IQ, and motivation. Draw a plausible causal DAG and identify a valid adjustment set for estimating the causal effect.",
    "domain": "causal",
    "difficulty": 5,
    "timeout_seconds": 300,
    "ground_truth": "Plausible DAG: Parental Income → Education, Parental Income → Earnings, IQ → Education, IQ → Earnings, Motivation → Education, Motivation → Earnings, Education → Earnings. Here Parental Income, IQ, and Motivation are confounders (they cause both Education and Earnings). A valid adjustment set: {Parental Income, IQ, Motivation}. By the backdoor criterion, conditioning on these blocks all backdoor paths from Education to Earnings. If Motivation is unmeasured, we have unobserved confounding and cannot identify the causal effect from observational data alone without additional assumptions (e.g., instrumental variables). A possible instrument: distance to nearest college (affects education but not earnings directly).",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["DAG", "backdoor-criterion", "confounding", "adjustment-set"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-003",
    "problem": "A hospital study finds that patients who receive a particular drug have higher mortality rates than those who don't. However, when the data is stratified by disease severity, the drug REDUCES mortality in both mild and severe cases. Explain this paradox.",
    "domain": "causal",
    "difficulty": 4,
    "timeout_seconds": 240,
    "ground_truth": "This is Simpson's Paradox. The drug is preferentially given to sicker patients (confounding by indication). Severe cases: high mortality (say 80% without drug, 70% with drug). Mild cases: low mortality (say 10% without drug, 5% with drug). But if 90% of drug recipients have severe disease vs 20% of non-recipients, the aggregate mortality can be higher for the drug group despite it helping within each stratum. The correct causal conclusion is that the drug is beneficial. The stratified analysis controls for the confounder (severity). The aggregate analysis is confounded. Resolution: condition on disease severity (a confounder) to get the correct causal estimate. This is why randomized controlled trials are the gold standard—they balance confounders.",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["simpson-paradox", "confounding-by-indication", "stratification"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-004",
    "problem": "A tech company runs an A/B test for a new recommendation algorithm. The treatment group shows 5% higher click-through rate (CTR). The p-value is 0.03. A data scientist claims there is a 97% probability that the new algorithm is better. Is this interpretation correct?",
    "domain": "causal",
    "difficulty": 4,
    "timeout_seconds": 240,
    "ground_truth": "This interpretation is INCORRECT. The p-value is NOT the probability that the null hypothesis is true (or 1-p that the alternative is true). The p-value = 0.03 means: IF the null hypothesis were true (no real difference), there would be a 3% probability of observing a result at least as extreme as the one obtained. The probability that the algorithm is actually better depends on: (1) the prior probability of improvement, (2) the statistical power, (3) the effect size. This is the classic p-value misinterpretation. To get P(algorithm is better | data), one needs Bayesian analysis. Additionally, consider: multiple testing, practical significance (is 5% CTR lift meaningful?), novelty effects, and whether the sample is representative.",
    "ground_truth_score": 0.0,
    "is_trap": true,
    "previously_unsolved": false,
    "tags": ["trap", "p-value", "statistical-inference", "AB-testing", "common-misconception"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-005",
    "problem": "Explain the difference between the Average Treatment Effect (ATE), the Average Treatment Effect on the Treated (ATT), and the Local Average Treatment Effect (LATE). When would each be the most relevant estimand?",
    "domain": "causal",
    "difficulty": 6,
    "timeout_seconds": 300,
    "ground_truth": "ATE = E[Y(1) - Y(0)] — the average causal effect across the entire population. Most relevant for universal policy decisions (e.g., should we mandate a vaccine for everyone?). ATT = E[Y(1) - Y(0) | T=1] — the average effect among those who actually received treatment. Most relevant when evaluating an existing program (e.g., did the job training program help those who enrolled?). ATE ≠ ATT when there is treatment effect heterogeneity correlated with selection. LATE = E[Y(1) - Y(0) | Compliers] — the average effect among 'compliers' in an instrumental variable (IV) design. Compliers are those who would take treatment when encouraged but not otherwise. Most relevant in IV studies (e.g., effect of military service on earnings using draft lottery as instrument, estimated only for those who served because they were drafted). Key insight: different estimands answer different policy questions, and the choice depends on the decision context.",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["treatment-effects", "ATE", "ATT", "LATE", "estimands"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-006",
    "problem": "Design a regression discontinuity study to estimate the causal effect of a scholarship on college GPA. The scholarship is awarded to students with SAT scores above 1400. Describe the key assumptions, potential threats to validity, and how you would implement the analysis.",
    "domain": "causal",
    "difficulty": 7,
    "timeout_seconds": 360,
    "ground_truth": "Design: Sharp RD with running variable = SAT score, cutoff = 1400, treatment = scholarship, outcome = college GPA. Key assumptions: (1) Continuity: potential outcomes E[Y(0)|X=x] and E[Y(1)|X=x] are continuous at x=1400. (2) No manipulation: students cannot precisely control their SAT score around the cutoff. (3) No compound treatment: nothing else changes discontinuously at 1400. Implementation: (1) Restrict to a bandwidth around 1400 (e.g., 1300-1500). (2) Fit local polynomial regression on each side of the cutoff. (3) The treatment effect is the discontinuity in the fitted values at x=1400. (4) Use optimal bandwidth selection (Imbens-Kalyanaraman). Threats: (1) Score manipulation (test retaking targeting 1400). (2) Other programs with same cutoff. (3) Functional form misspecification. Validation: test for discontinuities in pre-treatment covariates (demographics) at the cutoff; test for density discontinuity (McCrary test).",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["regression-discontinuity", "quasi-experiment", "causal-identification"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-007",
    "problem": "Using Pearl's do-calculus, explain the difference between P(Y|X) and P(Y|do(X)). Give a concrete example where these differ and explain why the distinction matters for causal reasoning.",
    "domain": "causal",
    "difficulty": 7,
    "timeout_seconds": 360,
    "ground_truth": "P(Y|X) is the conditional/observational probability: the distribution of Y among units where X was observed to take a particular value. P(Y|do(X)) is the interventional probability: the distribution of Y if we were to externally set X to a particular value, severing all causal arrows into X. Example: X = barometer reading, Y = storm occurrence, Z = atmospheric pressure. P(storm | barometer drops) is high because low pressure causes both. But P(storm | do(barometer drops)) — physically forcing the barometer down — has no effect on storms. The DAG: Z → X and Z → Y. Conditioning on X in P(Y|X) inherits information about Z. The do-operator in P(Y|do(X)) cuts the Z → X edge, so X carries no information about Z. P(Y|do(X)) = Σ_z P(Y|X,Z=z)P(Z=z) (backdoor adjustment), while P(Y|X) = Σ_z P(Y|X,Z=z)P(Z=z|X). This distinction is why observational correlations can be misleading for decision-making: we need interventional quantities for causal predictions.",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["do-calculus", "intervention", "pearl", "observation-vs-intervention"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  },
  {
    "task_id": "causal-infer-008",
    "problem": "A difference-in-differences study estimates the effect of a minimum wage increase on employment by comparing employment changes in a state that raised its minimum wage to a neighboring state that didn't, before and after the policy change. What is the key identifying assumption, and how can it be tested?",
    "domain": "causal",
    "difficulty": 6,
    "timeout_seconds": 300,
    "ground_truth": "The key identifying assumption is the parallel trends assumption: in the absence of the treatment (minimum wage increase), the treatment and control groups would have followed the same trend in the outcome (employment). This means any level differences between states are constant over time — it's the trends, not the levels, that must match. Testing: (1) Visual inspection: plot outcome trends for both groups in the pre-treatment period. If they are approximately parallel, the assumption is plausible. (2) Formal test: regress outcome on group, time, group×time interactions using only pre-treatment data. Test if pre-treatment group×time coefficients are jointly zero. (3) Placebo tests: apply the DiD estimator at fake treatment dates in the pre-period; estimates should be near zero. (4) Add group-specific linear time trends as robustness check. Threats: differential shocks to local economies, anticipation effects, compositional changes, spillover effects between states.",
    "ground_truth_score": 1.0,
    "is_trap": false,
    "previously_unsolved": false,
    "tags": ["difference-in-differences", "parallel-trends", "quasi-experiment", "policy-evaluation"],
    "source": "benchmark",
    "author": "ReasonForge Team",
    "created_at": "2026-01-15"
  }
]
